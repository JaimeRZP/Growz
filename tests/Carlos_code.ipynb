{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinguished-fifty",
   "metadata": {},
   "source": [
    "# Carlos Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classy import Class\n",
    "# define a theano Op for our likelihood function\n",
    "class bao_lkl(tt.Op):\n",
    "\n",
    "    \"\"\"\n",
    "    Specify what type of object will be passed and returned to the Op when it is\n",
    "    called. In our case we will be passing it a vector of values (the parameters\n",
    "    that define our model) and returning a single \"scalar\" value (the\n",
    "    log-likelihood)\n",
    "    \"\"\"\n",
    "    itypes = [tt.dvector] # expects a vector of parameter values when called\n",
    "    otypes = [tt.dscalar] # outputs a single scalar value (the log likelihood)\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialise the Op with various things that our log-likelihood function\n",
    "        requires. Below are the things that are needed in this particular\n",
    "        example.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        \"\"\"\n",
    "            \n",
    "        # Data from montepython_public/data/COMBINEDDR12_BAO_consensus_dM_Hz\n",
    "        self.rsfid = 147.78\n",
    "        cov = np.array([\n",
    "            [624.707, 23.729, 325.332, 8.34963, 157.386, 3.57778],\n",
    "            [23.729, 5.60873, 11.6429, 2.33996, 6.39263, 0.968056],\n",
    "            [325.332, 11.6429, 905.777, 29.3392, 515.271, 14.1013],\n",
    "            [8.34963, 2.33996, 29.3392, 5.42327, 16.1422, 2.85334],\n",
    "            [157.386, 6.39263, 515.271, 16.1422, 1375.12, 40.4327],\n",
    "            [3.57778, 0.968056, 14.1013, 2.85334, 40.4327, 6.25936]\n",
    "        ])\n",
    "        self.icov = np.linalg.inv(cov)\n",
    "        # BAO-only consensus results, Alam et al. 2016\n",
    "        self.z = np.array([0.38, 0.51, 0.61])\n",
    "        self.a = 1/(1+self.z)\n",
    "        # Vectors are multiplied by (rsfid/rs) so that: dM = dM*(rsfid/rs) \n",
    "        # and Hz = Hz*(rs/rsfid)\n",
    "        dM = np.array([1512.39, 1975.22, 2306.68])\n",
    "        Hz = np.array([81.2087, 90.9029, 98.9647])\n",
    "\n",
    "        data_vector = np.empty((dM.size + Hz.size), dtype=dM.dtype)\n",
    "        data_vector[0::2] = dM\n",
    "        data_vector[1::2] = Hz\n",
    "        \n",
    "        self.data = data_vector\n",
    "        self.model = Class()\n",
    "\n",
    "    def likelihood(self, theta):\n",
    "        if np.any(theta < 0):\n",
    "            return -np.inf\n",
    "\n",
    "        Omega_c, h = theta\n",
    "#         cosmo = ccl.Cosmology(Omega_c=Omega_c, Omega_b=0.045, h=h, sigma8=0.78, n_s=0.96,\n",
    "#                                transfer_function='boltzmann_class')\n",
    "#         Hz = ccl.background.h_over_h0(cosmo, self.a) * h * 100\n",
    "#         dM = ccl.background.comoving_angular_distance(cosmo, self.a)\n",
    "        \n",
    "#         params = {\n",
    "#         \"h\": cosmo[\"h\"],\n",
    "#         \"Omega_cdm\": cosmo[\"Omega_c\"],\n",
    "#         \"Omega_b\": cosmo[\"Omega_b\"],\n",
    "#         \"Omega_k\": cosmo[\"Omega_k\"],\n",
    "#         \"n_s\": cosmo[\"n_s\"],\n",
    "#         \"T_cmb\": cosmo['T_CMB']}\n",
    "    \n",
    "        params = {'h': h,\n",
    "                  'Omega_cdm': Omega_c}\n",
    "        \n",
    "        model = self.model\n",
    "        model.set(params)\n",
    "        try:\n",
    "            model.compute()\n",
    "        except:\n",
    "            model.struct_cleanup()\n",
    "            return -np.inf\n",
    "        rs = model.rs_drag()\n",
    "        dM = np.array([model.angular_distance(zi) * (1. + zi) for zi in self.z])\n",
    "        Hz = np.array([model.Hubble(zi) for zi in self.z]) * 2.99792458e8 / 1000.0\n",
    "        model.struct_cleanup()\n",
    "        model.empty()\n",
    "                \n",
    "        # Not sure how to compute r_s in CCL. Not included\n",
    "        th_vector = np.empty((dM.size + Hz.size), dtype=dM.dtype)\n",
    "        th_vector[0::2] = dM * self.rsfid / rs\n",
    "        th_vector[1::2] = Hz * rs / self.rsfid\n",
    "        \n",
    "        logl = -0.5 * (th_vector - self.data).dot(self.icov).dot(th_vector - self.data)\n",
    "        return logl\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        # the method that is used when calling the Op\n",
    "        theta, = inputs  # this will contain my variables\n",
    "\n",
    "        # call the log-likelihood function\n",
    "        logl = self.likelihood(theta)\n",
    "\n",
    "        outputs[0][0] = np.array(logl) # output the log-likelihood\n",
    "    \n",
    "\n",
    "logl = bao_lkl()\n",
    "    \n",
    "with pm.Model():\n",
    "    # uniform priors on m and c\n",
    "    Omega_c = pm.Normal('Omega_c', mu=0.26, sigma=0.25)\n",
    "    h = pm.Normal('h', mu=0.68, sigma=0.25)\n",
    "\n",
    "    # convert m and c to a tensor vector\n",
    "    theta = tt.as_tensor_variable([Omega_c, h])\n",
    "\n",
    "    # use a DensityDist (use a lamdba function to \"call\" the Op)\n",
    "    pm.Potential('likelihood', logl(theta))\n",
    "    #pm.Potential('likelihood', lambda v: logl(v), observed={'v': theta})\n",
    "\n",
    "    step = pm.Metropolis()\n",
    "    #trace = pm.sample(100, step=step, cores=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
