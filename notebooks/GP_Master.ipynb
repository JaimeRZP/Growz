{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "failing-relaxation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T09:37:00.756890Z",
     "start_time": "2021-12-15T09:36:58.108562Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "from pymc3.gp.util import plot_gp_dist\n",
    "import scipy as sp\n",
    "import pyccl as ccl\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import os\n",
    "import utils\n",
    "from make_data import MakeData\n",
    "from scipy.linalg import block_diag\n",
    "theano.config.exception_verbosity='high'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-infrastructure",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "antique-purse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T09:37:01.022803Z",
     "start_time": "2021-12-15T09:37:00.758722Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path:  /home/jaime/PhD/Growz/data/products\n",
      "Using Planck mean\n",
      "Making new DESI\n",
      "Multiplying error bars by  1\n",
      "Making new geoDESI\n",
      "Multiplying error bars by  1\n",
      "Making new groDESI\n",
      "Multiplying error bars by  1\n",
      "Found file for CC\n",
      "Found file for DSS\n",
      "Found file for BOSS\n",
      "Found file for geoBOSS\n",
      "Found file for groBOSS\n",
      "Found file for eBOSS\n",
      "Found file for geoeBOSS\n",
      "Found file for groeBOSS\n",
      "Found file for Wigglez\n",
      "Found file for DS17\n"
     ]
    }
   ],
   "source": [
    "z_max = 1110\n",
    "res = 200\n",
    "x_arr = np.linspace(0, np.log(1+z_max), res)\n",
    "dx = np.mean(np.diff(x_arr))\n",
    "z_arr = np.exp(x_arr)-1\n",
    "a_arr = 1./(1+z_arr)\n",
    "\n",
    "path = '/home/jaime/PhD/Growz/data/products' \n",
    "challenge = None #'cosmo51'\n",
    "if challenge is not None:\n",
    "    path += 'challenge/'+'cosmo{}_seed100{}'.format(challenge[-2], challenge[-1])\n",
    "\n",
    "print('data path: ', path)\n",
    "mean_path =  None #'LCDM_cosmo44_10000_10000'\n",
    "mean_mode = 'Planck'\n",
    "data_class = MakeData(z_max, res, path,\n",
    "                      cosmo_mode=mean_mode,\n",
    "                      cosmo_path=mean_path)\n",
    "c = data_class.c\n",
    "\n",
    "DESI = data_class.get_DESI(new=True, mode=None)\n",
    "geo_DESI = data_class.get_DESI(new=True, mode='geo')\n",
    "gro_DESI = data_class.get_DESI(new=True, mode='gro')\n",
    "WFIRST = data_class.get_WFIRST(new=True)\n",
    "CC = data_class.get_CC(new=False)\n",
    "DSS = data_class.get_DSS(new=False)\n",
    "BOSS = data_class.get_BOSS(new=False)\n",
    "geo_BOSS = data_class.get_BOSS(new=False, mode='geo')\n",
    "gro_BOSS = data_class.get_BOSS(new=False, mode='gro')\n",
    "eBOSS = data_class.get_eBOSS(new=False)\n",
    "geo_eBOSS = data_class.get_eBOSS(new=False, mode='geo')\n",
    "gro_eBOSS = data_class.get_eBOSS(new=False, mode='gro')\n",
    "Wigglez = data_class.get_Wigglez(new=False)\n",
    "DS17 = data_class.get_DS17(new=False)\n",
    "CMB = data_class.get_CMB(new=True)\n",
    "\n",
    "n_samples = 100\n",
    "n_tune = 100\n",
    "Planck = data_class.Planck\n",
    "z_planck = data_class.z_planck\n",
    "\n",
    "datadict = {'DESI': DESI,\n",
    "            'geo_DESI': geo_DESI,\n",
    "            'gro_DESI': gro_DESI,\n",
    "            'WFIRST': WFIRST,\n",
    "            'CC': CC,\n",
    "            'DS17': DS17, \n",
    "            'BOSS': BOSS,\n",
    "            'geo_BOSS': geo_BOSS,\n",
    "            'gro_BOSS': gro_BOSS,\n",
    "            'eBOSS': eBOSS,\n",
    "            'geo_eBOSS': geo_eBOSS,\n",
    "            'gro_eBOSS': gro_eBOSS,\n",
    "            'Wigglez': Wigglez,\n",
    "            'DSS': DSS,\n",
    "            'CMB': CMB}\n",
    "\n",
    "data_comb = 'CMB' # All, All_CMB, SDSS, SDSS_CMB, Add, Add_CMB\n",
    "data_combs = {'All': ['CC', 'DS17', 'BOSS', 'eBOSS', 'Wigglez', 'DSS'],\n",
    "             'All_CMB': ['CC', 'DS17', 'BOSS', 'eBOSS', 'Wigglez', 'DSS', 'CMB'],\n",
    "             'All_CMB_NODSS': ['CC', 'DS17', 'BOSS', 'eBOSS', 'Wigglez', 'CMB'],\n",
    "             'All_CMB_geo': ['CC', 'DS17', 'geo_BOSS', 'geo_eBOSS', 'CMB'],\n",
    "             'All_gro': ['gro_BOSS', 'gro_eBOSS', 'Wigglez', 'DSS'],\n",
    "             'All_CMB_gro': ['gro_BOSS', 'gro_eBOSS', 'Wigglez', 'DSS', 'CMB'],\n",
    "             'SDSS': ['BOSS', 'eBOSS'],\n",
    "             'SDSS_CMB': ['BOSS', 'eBOSS', 'CMB'],\n",
    "             'Add': ['CC', 'DS17', 'Wigglez', 'DSS'],\n",
    "             'Add_CMB': ['CC', 'DS17', 'Wigglez', 'DSS', 'CMB'],\n",
    "             'DESI_CMB': ['DESI', 'CMB'], \n",
    "             'DESI_CMB_geo': ['geo_DESI', 'CMB'], \n",
    "             'DESI_gro': ['gro_DESI'], \n",
    "             'WFIRST_CMB': ['WFIRST', 'CMB'],\n",
    "             'CMB': ['CMB']}\n",
    "\n",
    "datasets = data_combs[data_comb]\n",
    "\n",
    "need_dM = ['DESI', 'geo_DESI', 'BOSS', 'eBOSS', 'geo_BOSS', 'geo_eBOSS',\n",
    "           'Wigglez', 'DS17', 'CMB', 'FCMB']\n",
    "need_fs8 = ['DESI', 'gro_DESI', 'BOSS', 'eBOSS', 'gro_BOSS', \n",
    "            'gro_eBOSS', 'Wigglez', 'DSS']\n",
    "need_rd = ['BOSS', 'eBOSS', 'geo_BOSS', 'geo_eBOSS', 'CMB']\n",
    "\n",
    "if any(dataset in datasets for dataset in need_dM):\n",
    "    get_dM=True \n",
    "else:\n",
    "    get_dM=False\n",
    "    \n",
    "if any(dataset in datasets for dataset in need_fs8):\n",
    "    get_fs8=True\n",
    "else:\n",
    "    get_fs8=False\n",
    "    \n",
    "if any(dataset in datasets for dataset in need_rd):\n",
    "    get_rd = True\n",
    "else:\n",
    "    get_rd = False\n",
    "        \n",
    "#Data\n",
    "data = np.array([])\n",
    "data_cov = np.array([])\n",
    "for dataset_name in datasets:\n",
    "    dataset = datadict[dataset_name]\n",
    "    data = np.concatenate([data, dataset['data']])\n",
    "    data_cov = block_diag(data_cov, dataset['cov'])\n",
    "data_cov = data_cov[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-latest",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resident-condition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T09:37:09.388220Z",
     "start_time": "2021-12-15T09:37:01.024589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding CMB\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    ℓ = pm.Uniform(\"ℓ\", 0.01, 6) \n",
    "    η = pm.HalfNormal(\"η\", sigma=0.2) \n",
    "    A0 = pm.Normal(\"A0\", 1, 0.2)\n",
    "    wm0_mean = data_class.wm0 \n",
    "    wr0 = data_class.wr0\n",
    "    wL0 = data_class.wL0 \n",
    "    gp_cov = η ** 2 * pm.gp.cov.ExpQuad(1, ℓ) + pm.gp.cov.WhiteNoise(1e-5)\n",
    "    gp = pm.gp.Latent(cov_func=gp_cov)\n",
    "    \n",
    "    #Mean of the gp\n",
    "    H = pm.Deterministic('H', 100*tt.sqrt(wm0_mean*(1+z_arr)**3+wr0*(1+z_arr)**4+wL0))\n",
    "    \n",
    "    #Set up Gaussian process\n",
    "    DH_gp = gp.prior(\"DH_gp\", X=x_arr[:, None]) \n",
    "    H_gp = pm.Deterministic(\"H_gp\", tt.as_tensor_variable(A0*H*(1+DH_gp)))\n",
    "    H0_gp = pm.Deterministic(\"H0_gp\", tt.as_tensor_variable(H_gp[0]))\n",
    "    \n",
    "    if get_dM:\n",
    "        dH_gp = pm.Deterministic(\"dH\", tt.as_tensor_variable((c/1000)/H_gp))\n",
    "        dM_rec_gp = tt.zeros(len(z_arr)+1)\n",
    "        dM_rec_gp = tt.inc_subtensor(dM_rec_gp[1:],\n",
    "                  tt.as_tensor_variable(dx*tt.cumsum(dH_gp*(1+z_arr))))\n",
    "        dM_trap_gp = tt.as_tensor_variable(0.5*(dM_rec_gp[1:]+dM_rec_gp[:-1])-0.5*dM_rec_gp[1])\n",
    "        dM_gp = pm.Deterministic('dM_gp', dM_trap_gp)\n",
    "        dA_gp = pm.Deterministic('dA_gp', dM_gp/(1+z_arr))\n",
    "        dL_gp = pm.Deterministic('dL_gp', dM_gp*(1+z_arr))\n",
    "        \n",
    "    if get_rd:\n",
    "        rd_gp = pm.Normal(\"rd_gp\", 150, 5)\n",
    "        \n",
    "    if get_fs8:\n",
    "        Wm0 = pm.Uniform(\"Wm0\", 0., 1.)\n",
    "        s80 = pm.Normal(\"s80\", 0.8, 0.5)\n",
    "        E = H_gp/H_gp[0]\n",
    "        xx = x_arr[::-1]\n",
    "        ee = E[::-1]\n",
    "        aa = np.exp(-xx)\n",
    "        dx = np.mean(np.diff(xx))\n",
    "\n",
    "        nz = len(aa)\n",
    "        dd = tt.zeros(nz)\n",
    "        yy = tt.zeros(nz)\n",
    "        dd = tt.inc_subtensor(dd[0], aa[0])\n",
    "        yy = tt.inc_subtensor(yy[0], aa[0]**3*E[0])\n",
    "\n",
    "        for i in range(nz-1):\n",
    "            A0 = -1.5*Wm0/(aa[i]*ee[i])\n",
    "            B0 = -1./(aa[i]**2*ee[i])\n",
    "            A1 = -1.5*Wm0/(aa[i+1]*ee[i+1])\n",
    "            B1 = -1./(aa[i+1]**2*ee[i+1])\n",
    "            yy = tt.inc_subtensor(yy[i+1], (1+0.5*dx**2*A0*B0)*yy[i]+0.5*(A0+A1)*dx*dd[i])\n",
    "            dd = tt.inc_subtensor(dd[i+1],0.5*(B0+B1)*dx*yy[i]+(1+0.5*dx**2*A0*B0)*dd[i])\n",
    "        \n",
    "        y = tt.as_tensor_variable(yy[::-1])\n",
    "        d = tt.as_tensor_variable(dd[::-1])\n",
    "        \n",
    "        fs8_gp = pm.Deterministic('fs8_gp', s80*y/(a_arr**2*E*d[0]))\n",
    "        s8_gp = pm.Deterministic('s8_gp', s80*d/d[0])\n",
    "        \n",
    "    theory = tt.as_tensor_variable([])\n",
    "    \n",
    "#Modules\n",
    "if 'DESI' in datasets:\n",
    "    print('Adding DESI')\n",
    "    with model:\n",
    "        DESI_H = pm.Deterministic('DESI_H',\n",
    "                 tt.as_tensor_variable(H_gp[DESI['idx']]+(H_gp[DESI['idx']+1]-H_gp[DESI['idx']])*DESI['U']))\n",
    "        DESI_dA = pm.Deterministic('DESI_dA',\n",
    "                  tt.as_tensor_variable(dA_gp[DESI['idx']]+(dA_gp[DESI['idx']+1]-dA_gp[DESI['idx']])*DESI['U']))\n",
    "        DESI_fs8 = pm.Deterministic('DESI_fs8',\n",
    "                   tt.as_tensor_variable(fs8_gp[DESI['idx']]+(fs8_gp[DESI['idx']+1]-fs8_gp[DESI['idx']])*DESI['U']))\n",
    "        theory = tt.concatenate([theory, DESI_H, DESI_dA, DESI_fs8])\n",
    "\n",
    "if 'gro_DESI' in datasets:\n",
    "    print('Adding DESI_gro')\n",
    "    with model:\n",
    "        DESI_fs8 = pm.Deterministic('DESI_fs8',\n",
    "                   tt.as_tensor_variable(fs8_gp[DESI['idx']]+(fs8_gp[DESI['idx']+1]-fs8_gp[DESI['idx']])*DESI['U']))\n",
    "        theory = tt.concatenate([theory, DESI_fs8])\n",
    "\n",
    "if 'geo_DESI' in datasets:\n",
    "    print('Adding DESI_geo')\n",
    "    with model:\n",
    "        DESI_H = pm.Deterministic('DESI_H',\n",
    "                 tt.as_tensor_variable(H_gp[DESI['idx']]+(H_gp[DESI['idx']+1]-H_gp[DESI['idx']])*DESI['U']))\n",
    "        DESI_dA = pm.Deterministic('DESI_dA',\n",
    "                  tt.as_tensor_variable(dA_gp[DESI['idx']]+(dA_gp[DESI['idx']+1]-dA_gp[DESI['idx']])*DESI['U']))\n",
    "        theory = tt.concatenate([theory, DESI_H, DESI_dA])\n",
    "        \n",
    "if 'WFIRST' in datasets:\n",
    "    print('Adding WFIRST')\n",
    "    with model:\n",
    "        WFIRST_E = pm.Deterministic('WFIRST_E',\n",
    "                   tt.as_tensor_variable(E_gp[WFIRST['idx']]+(E_gp[WFIRST['idx']+1]-E_gp[WFIRST['idx']])*WFIRST['U']))\n",
    "        theory = tt.concatenate([theory, WFIRST_E])\n",
    "\n",
    "if 'CC' in datasets:\n",
    "    print('Adding CCs')\n",
    "    with model:\n",
    "        CC_H = pm.Deterministic(\"CC_H\",\n",
    "               tt.as_tensor_variable(H_gp[CC['idx']]+(H_gp[CC['idx']+1]-H_gp[CC['idx']])*CC['U']))\n",
    "        theory = tt.concatenate([theory, CC_H])\n",
    "        \n",
    "if 'DS17' in datasets:\n",
    "    print('Adding Pantheon')\n",
    "    with model:\n",
    "        M = pm.Normal('M', mu=-19.0, sigma=3)\n",
    "        DS17_dL = tt.as_tensor_variable(dL_gp[DS17['idx']]+(dL_gp[DS17['idx']+1]-dL_gp[DS17['idx']])*DS17['U'])\n",
    "        DS17_u = pm.Deterministic(\"DS17_dL\",\n",
    "                 tt.as_tensor_variable(5*tt.log10(DS17_dL)+25+M))\n",
    "        theory = tt.concatenate([theory, DS17_u])\n",
    "        \n",
    "if 'BOSS' in datasets:\n",
    "    print('Adding BOSS')\n",
    "    with model:\n",
    "        B_H = tt.as_tensor_variable(H_gp[BOSS['idx']]+(H_gp[BOSS['idx']+1]-H_gp[BOSS['idx']])*BOSS['U'])\n",
    "        B_dM = tt.as_tensor_variable(dM_gp[BOSS['idx']]+(dM_gp[BOSS['idx']+1]-dM_gp[BOSS['idx']])*BOSS['U'])\n",
    "        B_fs8 = pm.Deterministic(\"B_fs8\", \n",
    "                   tt.as_tensor_variable(fs8_gp[BOSS['idx']]+(fs8_gp[BOSS['idx']+1]-fs8_gp[BOSS['idx']])*BOSS['U']))\n",
    "        #Get alpha_perp and alpha_para \n",
    "        B_para = pm.Deterministic(\"B_para\", B_H*rd_gp/BOSS['rd'])\n",
    "        B_perp = pm.Deterministic(\"B_perp\", B_dM*BOSS['rd']/rd_gp)\n",
    "        theory = tt.concatenate([theory, B_para, B_perp, B_fs8])\n",
    "        \n",
    "if 'geo_BOSS' in datasets:\n",
    "    print('Adding geo_BOSS')\n",
    "    with model:\n",
    "        B_H = tt.as_tensor_variable(H_gp[BOSS['idx']]+(H_gp[BOSS['idx']+1]-H_gp[BOSS['idx']])*BOSS['U'])\n",
    "        B_dM = tt.as_tensor_variable(dM_gp[BOSS['idx']]+(dM_gp[BOSS['idx']+1]-dM_gp[BOSS['idx']])*BOSS['U'])\n",
    "        #Get alpha_perp and alpha_para \n",
    "        B_para = pm.Deterministic(\"B_para\", B_H*rd_gp/BOSS['rd'])\n",
    "        B_perp = pm.Deterministic(\"B_perp\", B_dM*BOSS['rd']/rd_gp)\n",
    "        theory = tt.concatenate([theory, B_para, B_perp])\n",
    "        \n",
    "if 'gro_BOSS' in datasets:\n",
    "    print('Adding gro_BOSS')\n",
    "    with model:\n",
    "        B_fs8 = pm.Deterministic(\"B_fs8\", \n",
    "                   tt.as_tensor_variable(fs8_gp[BOSS['idx']]+(fs8_gp[BOSS['idx']+1]-fs8_gp[BOSS['idx']])*BOSS['U']))\n",
    "        theory = tt.concatenate([theory, B_fs8])\n",
    "        \n",
    "if 'eBOSS' in datasets:\n",
    "    print('Adding eBOSS')\n",
    "    with model:\n",
    "        eB_dH = tt.as_tensor_variable(dH_gp[eBOSS['idx']]+(dH_gp[eBOSS['idx']+1]-dH_gp[eBOSS['idx']])*eBOSS['U'])\n",
    "        eB_dM = tt.as_tensor_variable(dM_gp[eBOSS['idx']]+(dM_gp[eBOSS['idx']+1]-dM_gp[eBOSS['idx']])*eBOSS['U'])\n",
    "        eB_fs8 = pm.Deterministic(\"eB_fs8\", \n",
    "                   tt.as_tensor_variable(fs8_gp[eBOSS['idx']]+(fs8_gp[eBOSS['idx']+1]-fs8_gp[eBOSS['idx']])*eBOSS['U']))\n",
    "        eB_para = pm.Deterministic(\"eB_para\", eB_dH/rd_gp)\n",
    "        eB_perp = pm.Deterministic(\"eB_perp\", eB_dM/rd_gp)\n",
    "        theory = tt.concatenate([theory, eB_para, eB_perp, eB_fs8])\n",
    "        \n",
    "if 'geo_eBOSS' in datasets:\n",
    "    print('Adding geo_eBOSS')\n",
    "    with model:\n",
    "        eB_dH = tt.as_tensor_variable(dH_gp[eBOSS['idx']]+(dH_gp[eBOSS['idx']+1]-dH_gp[eBOSS['idx']])*eBOSS['U'])\n",
    "        eB_dM = tt.as_tensor_variable(dM_gp[eBOSS['idx']]+(dM_gp[eBOSS['idx']+1]-dM_gp[eBOSS['idx']])*eBOSS['U'])\n",
    "        eB_para = pm.Deterministic(\"eB_para\", eB_dH/rd_gp)\n",
    "        eB_perp = pm.Deterministic(\"eB_perp\", eB_dM/rd_gp)\n",
    "        theory = tt.concatenate([theory, eB_para, eB_perp])\n",
    "\n",
    "if 'gro_eBOSS' in datasets:\n",
    "    print('Adding gro_eBOSS')\n",
    "    with model:\n",
    "        eB_fs8 = pm.Deterministic(\"eB_fs8\", \n",
    "                   tt.as_tensor_variable(fs8_gp[eBOSS['idx']]+(fs8_gp[eBOSS['idx']+1]-fs8_gp[eBOSS['idx']])*eBOSS['U']))\n",
    "        theory = tt.concatenate([theory, eB_fs8])\n",
    "\n",
    "if 'Wigglez' in datasets:\n",
    "    print('Adding Wigglez')\n",
    "    with model:\n",
    "        Wigglez_fs8 = pm.Deterministic(\"Wigglez_fs8\",\n",
    "                    tt.as_tensor_variable(fs8_gp[Wigglez['idx']]+(fs8_gp[Wigglez['idx']+1]-fs8_gp[Wigglez['idx']])*Wigglez['U']))\n",
    "        theory = tt.concatenate([theory, Wigglez_fs8])\n",
    "\n",
    "if 'DSS' in datasets:\n",
    "    print('Adding DSS')\n",
    "    with model:\n",
    "        DSS_fs8 = pm.Deterministic(\"fs8_eBOSS\", tt.as_tensor_variable(fs8_gp[DSS['idx']]))\n",
    "        theory = tt.concatenate([theory, DSS_fs8])\n",
    "\n",
    "if 'CMB' in datasets:\n",
    "    print('Adding CMB')\n",
    "    with model:\n",
    "        dM_star = tt.as_tensor_variable(dM_gp[CMB['idx']]+(dM_gp[CMB['idx']+1]-dM_gp[CMB['idx']])*CMB['U'])\n",
    "        t100 = pm.Deterministic('t100', 100*rd_gp/dM_star) \n",
    "        theory = tt.concatenate([theory, t100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honest-cleanup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:00:10.956357Z",
     "start_time": "2021-12-15T09:37:09.390063Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 100 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: divide by zero encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: invalid value encountered in multiply\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [rd_gp, DH_gp_rotated_, A0, η, ℓ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105' class='' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      13.12% [105/800 16:48<1:51:12 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: overflow encountered in exp\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: overflow encountered in square\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: overflow encountered in square\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/home/jaime/anaconda3/lib/python3.9/site-packages/theano/tensor/elemwise.py:826: RuntimeWarning: overflow encountered in exp\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_msg_pipe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7887/1615769188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlkl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMvNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inferencedata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_accept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparallel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiscard_tuned_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m             \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough samples to build a trace.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "#Sampling\n",
    "with model:\n",
    "    lkl= pm.MvNormal(\"lkl\", mu=theory, cov=data_cov, observed=data)\n",
    "    trace = pm.sample(n_samples, return_inferencedata=True, tune=n_tune, target_accept=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-acquisition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T14:46:49.732651Z",
     "start_time": "2021-12-16T14:46:49.649580Z"
    }
   },
   "outputs": [],
   "source": [
    "#print r-stat\n",
    "print(pm.summary(trace)['r_hat'][[\"Wm0\", \"η\"]])\n",
    "print(pm.summary(trace)['mean'][[\"Wm0\", \"ℓ\", \"η\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-locator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:05:04.054930Z",
     "start_time": "2021-12-15T10:05:04.032795Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save\n",
    "filename = data_comb\n",
    "if mean_mode is not None:\n",
    "    filename += '_'+mean_mode\n",
    "if challenge is not None:\n",
    "    filename += '_'+challenge\n",
    "    \n",
    "filename += '_{}_{}'.format(n_samples, n_tune)\n",
    "print(filename)\n",
    "\n",
    "n = np.array(trace.posterior[\"η\"]).flatten()\n",
    "l = np.array(trace.posterior[\"ℓ\"]).flatten()\n",
    "A0 = np.array(trace.posterior[\"A0\"]).flatten()\n",
    "DHz = np.array(trace.posterior[\"DH_gp\"])\n",
    "DHz = DHz.reshape(-1, DHz.shape[-1])\n",
    "Hz =np.array(trace.posterior[\"H_gp\"])\n",
    "Hz = Hz.reshape(-1, Hz.shape[-1])\n",
    "H0_gp = np.array(trace.posterior[\"H0_gp\"]).flatten()\n",
    "\n",
    "if get_dM:\n",
    "    dMz = np.array(trace.posterior[\"dM_gp\"])\n",
    "    dMz = dMz.reshape(-1, dMz.shape[-1])\n",
    "else:\n",
    "    dMz = None\n",
    "\n",
    "if get_rd:\n",
    "    rd = np.array(trace.posterior[\"rd_gp\"]).flatten()\n",
    "else:\n",
    "    rd = None\n",
    "    \n",
    "if get_fs8:\n",
    "    s8z = np.array(trace.posterior[\"s8_gp\"])\n",
    "    s8z = s8z.reshape(-1, s8z.shape[-1])\n",
    "    fs8z = np.array(trace.posterior[\"fs8_gp\"])\n",
    "    fs8z = fs8z.reshape(-1, fs8z.shape[-1])\n",
    "    Omega_m = np.array(trace.posterior[\"Wm0\"]).flatten()\n",
    "    s80 = np.array(trace.posterior[\"s80\"]).flatten()\n",
    "    S80 = s80*np.sqrt(Omega_m/0.3)\n",
    "else: \n",
    "    s8z = None \n",
    "    fs8z = None\n",
    "    Omega_m = None\n",
    "    s80 = None\n",
    "    S80 = None\n",
    "\n",
    "if 'DS17' in datasets:\n",
    "    M = np.array(trace.posterior[\"M\"]).flatten()\n",
    "else:\n",
    "    M = None\n",
    "\n",
    "os.mkdir(filename)\n",
    "np.savez(os.path.join(filename,'samples.npz'), \n",
    "         z_arr = z_arr,\n",
    "         n=n,\n",
    "         l=l,\n",
    "         A0=A0,\n",
    "         DHz = DHz,\n",
    "         Hz=Hz,\n",
    "         dMz=dMz,\n",
    "         s8z=s8z,\n",
    "         fs8z=fs8z,\n",
    "         H0_gp=H0_gp,\n",
    "         Omega_m=Omega_m,\n",
    "         s80=s80,\n",
    "         S80=S80,\n",
    "         rd=rd,\n",
    "         M=M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-optimum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:00:42.810263Z",
     "start_time": "2021-12-15T10:00:42.805522Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_m_s(rows):\n",
    "    cols = np.transpose(rows)\n",
    "    means = np.array([])\n",
    "    sigmas = np.array([])\n",
    "    for col in cols:\n",
    "        mean = np.mean(col)\n",
    "        sigma = np.std(col)\n",
    "        means = np.append(means, mean)\n",
    "        sigmas = np.append(sigmas, sigma)\n",
    "    return means, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-baking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:00:43.059885Z",
     "start_time": "2021-12-15T10:00:43.044448Z"
    }
   },
   "outputs": [],
   "source": [
    "DHz = np.array(trace.posterior[\"DH_gp\"])\n",
    "DHz = DHz.reshape(-1, DHz.shape[-1])\n",
    "DH_m, DH_s = get_m_s(DHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-spank",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:00:44.037436Z",
     "start_time": "2021-12-15T10:00:43.552638Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(z_arr,  DH_m, color ='b')\n",
    "plt.fill_between(z_arr, DH_m+DH_s,\n",
    "                 DH_m-DH_s, color='b', alpha=.5)\n",
    "plt.xscale('log')\n",
    "plt.xlim(0, 1110)\n",
    "plt.title('$\\delta$H(z)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-therapy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:02:15.208095Z",
     "start_time": "2021-12-15T10:02:14.953874Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = fig.gca()\n",
    "\n",
    "plot_gp_dist(ax, trace.posterior[\"H_gp\"][0, :, :], z_arr[:, None])\n",
    "plt.plot(z_arr, data_class.H_arr, 'b-.', label='formula')\n",
    "\n",
    "# plot the data and the true latent function\n",
    "#ax.plot(z_arr_f[:, None], H_arr_f, \"dodgerblue\", lw=3, label=r'$LCDM$')\n",
    "if 'CC' in datasets:\n",
    "    plt.errorbar(CC['z'], CC['data'], yerr = CC['err'], fmt='bo', label='CC')\n",
    "if 'FCMB' in datasets:\n",
    "    plt.errorbar(FCMB['z'], FCMB['data'], yerr = FCMB['err'], fmt='go', label='FCMB')\n",
    "if 'BOSS' in datasets:\n",
    "    plt.errorbar(BOSS['z'], BOSS['para_data'], yerr=BOSS['para_err'], fmt='ro', label='BOSS')\n",
    "if 'eBOSS' in datasets:\n",
    "    plt.errorbar(eBOSS['z'], c/1000/(eBOSS['para_data']*eBOSS['rd']), yerr = 1/eBOSS['rd']/(np.array([0.47])), fmt='mo', label='eBOSS')\n",
    "if 'DESI' or 'H_DESI' in datasets:\n",
    "    plt.errorbar(H_DESI['z'], H_DESI['data'], yerr = H_DESI['err'], fmt='bo', label='DESI')\n",
    "\n",
    "# axis labels and title\n",
    "plt.xlim(0, 2.5)\n",
    "plt.ylim(50, 300)\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"H(z)\")\n",
    "plt.title(\"H(z)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-header",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:02:28.388661Z",
     "start_time": "2021-12-15T10:02:28.365987Z"
    }
   },
   "outputs": [],
   "source": [
    "from getdist import plots, MCSamples\n",
    "def make_samples(file, names, ranges, label):\n",
    "    namess = []\n",
    "    labels = []\n",
    "    samples = []\n",
    "    for name in names:\n",
    "        if name in file.keys():\n",
    "            namess.append(name) \n",
    "            labels.append(labels_dict[name]) \n",
    "            samples.append(file[name]) \n",
    "        \n",
    "    return MCSamples(samples=samples, names=namess, labels=labels, label=label, ranges=ranges,\n",
    "                    settings={'mult_bias_correction_order':0,'smooth_scale_2D':0.3, 'smooth_scale_1D':0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-israeli",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:02:28.622953Z",
     "start_time": "2021-12-15T10:02:28.616543Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_dict = {'n': '\\eta',\n",
    "               'l': 'l',\n",
    "               'A0': 'A_0',\n",
    "               'n_H': '\\eta_H',\n",
    "               'l_H': 'l_H',\n",
    "               'n_Xi': '\\eta_{Xi}',\n",
    "               'l_Xi': 'l_{Xi}',\n",
    "               'H0': 'H_0',\n",
    "               'H0_gp': 'H_0',\n",
    "               'omega_m': '\\omega_m',\n",
    "               'Omega_m': '\\Omega_m',\n",
    "               'Omega_m_mean': '\\Omega_m^{mean}',\n",
    "               'omega_b': '\\omega_b',\n",
    "               'Omega_m': '\\Omega_m',\n",
    "               'Omega_b': '\\Omega_b',\n",
    "               's80': '\\sigma_8',\n",
    "               'S80': 'S_8',\n",
    "               'rd': 'r_s',\n",
    "               'M': 'M'}\n",
    "names_All = ['n', 'l', 'n_H', 'l_H', 'n_Xi', 'l_Xi', 'A0',\n",
    "             'H0', 'H0_gp',  'Omega_m', 'omega_m', 'Omega_m_mean',\n",
    "             'omega_b', 'Omega_m', 'Omega_b', 's80', 'S80', 'M']\n",
    "#ranges = {'l':[0.001, 7], 'omega_b': [0.022, 0.023]}\n",
    "ranges = {'l':[0.001, 7], 'Omega_m':[0.00, 0.4], 'omega_b':[0.015, 0.03]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-wheel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:02:29.354984Z",
     "start_time": "2021-12-15T10:02:29.340827Z"
    }
   },
   "outputs": [],
   "source": [
    "run = np.load(filename+'/samples.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-logan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:02:29.743745Z",
     "start_time": "2021-12-15T10:02:29.731049Z"
    }
   },
   "outputs": [],
   "source": [
    "run_samples = make_samples(run, ['n', 'l', 'Omega_m', 's80', 'S80'],\n",
    "                               ranges, 'Fiducial - CMB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-credit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-15T10:02:30.213587Z",
     "start_time": "2021-12-15T10:02:30.197704Z"
    }
   },
   "outputs": [],
   "source": [
    "g = plots.getSubplotPlotter(subplot_size=2.5)\n",
    "g.triangle_plot([run_samples],\n",
    "                filled=True,\n",
    "                markers={'H0':100*data_class.cosmo.h(),\n",
    "                         'omega_m': data_class.cosmo.Omega_m()*data_class.cosmo.h()**2,\n",
    "                         's80': data_class.cosmo.sigma8(), \n",
    "                         'S80': data_class.cosmo.sigma8()*np.sqrt(data_class.cosmo.Omega_m()/0.3)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
